[{"title":"CVPR 2020 Social-STGCNN：基于图卷积的行人轨迹预测","date":"2022-07-12T14:24:09.555Z","url":"/2022/07/12/CVPR%202020%20_%20Social-STGCNN%EF%BC%9A%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%8D%B7%E7%A7%AF%E7%9A%84%E8%A1%8C%E4%BA%BA%E8%BD%A8%E8%BF%B9%E9%A2%84%E6%B5%8B/","categories":[[" ",""]],"content":"原文链接：Social-STGCNN: A Social Spatio-Temporal Graph Convolutional NeuralNetwork for Human Trajectory Prediction代码链接：代码 有一段时间没有更新博客了，这一段时间我在干嘛呢？回想起来除了每周定时的007外，只是单纯的懒。在写作风格上，坚持靠近于算法层面，而不是单纯的文章翻译、代码解析。那废话不多说，我们开始吧！ 一、数据是怎样被处理的呢？在涉及数据处理的时候，文字性的表达效果十分有限。举例来说，你会面对7个不同的场景，每个场景就是一段视频，每段视频由许多帧组成，每帧中存在许多行人，每位行人又有不同的运动轨迹，每条轨迹又有不同的特征。那如果你要做实验，你要怎么处理这一块复杂的数据？你可能会告诉我说，找到对标的实验代码，以它为框架进行修改不就ok。没有错，我的想法同你一样，所以说你为什么能看到我的博客。话说回来，即便有了前人的代码框架，你也需要明白数据处理的逻辑。总结来说，在&#x3D;&#x3D;Social-STGCNN&#x3D;&#x3D;当中，数据会被这样处理：为了便于叙述，我们假定只考虑一个场景，并且假定读者已经看过代码，下面的叙述才不会让你感到困惑。在这个场景中，或说这段视频中，存在很多帧，那首先你要做的事是先把每帧处理成对应的&#x3D;&#x3D;帧ID&#x3D;&#x3D;。举例来说，第0帧对应帧ID：0 ，第十帧对应帧ID：1，第20帧对应帧ID：2，……，第14390帧对应帧ID：933。为什么要这样处理呢？很显然不这样处理后续没法进行呀，这就好比每个人都有自己的姓名一样。紧接着，给每帧标上序号以后，就要确定该帧 &#x2F; 该帧ID下所有行人轨迹吧。注意：这里的所有人可重复。什么意思呢？假设在第0帧下有10个人，这10个人可不是只存在于第0帧下，第10帧下可以存在这批人。OK，我想你明白我在说什么。总结来说，我们现在将数据处理成了什么模样呢？我们给每帧标注了对应的ID，并且找到了该帧下的所有行人。 接下来该怎么办呢?在上述处理的数据基础上，我们要进一步将其处理成mini-batch。怎么做呢？在帧ID上，我们以长度20为标准，步长为1进行Sample，这样长度为933的帧ID就被处理成了915个mini-batch。看到这你会不会疑问说915怎么得到的呢？我想留给读者思考会比较有意义，或者思考后在评论区@我吧。Anyway，现在得到了915个mini-batch，那我想问问读者朋友，每个mini-batch的维度是(20,4)吗？显然不会是(20,4)，因为我们刚才有交代过是步长为1逐步取得的数据嘛，换句话说就是每个mini-batch下的行人也是可重复的。下一步就很直接了，给每个mini-batch标上ID吧，标上ID后我们就要数一数每个mini-batch下都有几个人了，举例来说，mini-batch ID 0下有16个人，mini-batch ID 1下有16个人，…… ，mini-batch ID 915下有48个人；人数确定好后，就要进一步确定在每个ID下的每个人是否都符合&#x3D;&#x3D;要求&#x3D;&#x3D;。要求是什么呢？要求就是该行人尾帧对应的帧ID减去该行人首帧对应的帧ID要等于20。那为什么要这样做呢？你想想看我们的&#x3D;&#x3D;Social-STGCNN&#x3D;&#x3D;算法用的是图卷积，必须保证每一个节点都是相同的帧数才行，不然在时序建模上会出错。举例来说，mini-batch ID 0下有16个人只有4人符合要求，mini-batch ID 1下有16个人只有3人符合要求，……，mini-batch ID 915下有48个人只有12人符合要求。那符合要求的行人数目才是最终mini-batch所包含的人数，所以自然而然就得到实际上每个mini-batch的维度了，举例来说，mini-batch ID 0下有16个人只有4人符合要求，那它的维度就是(4,2,20)；mini-batch ID 1下有16个人只有3人符合要求，那它的维度就是(3,2,20)，……，mini-batch ID 915下有48个人只有12人符合要求，那它的维度就是(12,2,20) 紧接着就很自然了，将每个mini-batch转换为Graph了，不过要注意，&#x3D;&#x3D;代码中将前8帧与后12帧分开了&#x3D;&#x3D;，希望读者明白我在说什么。 二、ST_GCNN算法&#x3D;&#x3D;ST-GCNN&#x3D;&#x3D;算法是一件想象力十足的事，为什么这样说呢？因为你去看它论文里给你的网络架构，很形象又很抽象，可能这就是定会大佬的风格吧。我最近喜欢干这样一件事，就是根据代码自己画它的网络框架，如果读者能够自己动动手，我相信你会有更深的理解。 首先假定读者朋友已经知道Sequence是怎样构成Spatio-Temporal Graph的了，为什么要先假定，因为我的夜宵到了，这里就…。好，GCN的好处是降低了参数量，并且可以多帧的输入。现在假定下图所示的mini-batch中只有4个人，他们的交互关系与轨迹构成了一个时空图。有Graph我们可以得到其特征矩阵X，邻接矩阵A。注意：这里的特征是每个行人的相对位置，邻接矩阵做了论文中所述的加权处理与归一化处理。有了这俩宝贝，先喂给我们的GCN模块，也就是说GCN的输入来自两方面：特征矩阵X和邻接矩阵A。GCN实际上在干一件什么事呢？GCN实际上就是在提取行人的轨迹特征，并在最后实现图嵌入。GCN的输出会被喂给TCN，这一步主要是提取行人间的时域信息。那怎么做呢？对于在图上的时序信息的提取，我们可以用卷积的方式进行处理。举例来说，一个大小为(3,1)的卷积核在图的每个节点上从上到下、从左自右的滑动，得到了行人的时序信息。实际上，卷积的实质就是消息聚合。到这一步，就得到了聚合有行人间交互的时空特征了，但是一个很直接的想法是，做一个residual会不会更好呢？这样就能叠加一个全局的信息在里面，实际上代码也是这么做的，但是光看论文可啥也没说。OK,做到这一步那轨迹特征就编码完了，就下来就该解码了吧。解码器由多个具体来说是六个TPCNN构成。别被名字糊住了，TPCNN就是在时域维度上做卷积的CNN。第一层的TPCNN将输入8维映射到12维；中间四层TPCNN对时域特征做进一步的提取，输入12维输出12维，并且附带residual结构；经最后一层TPCNN输出概率分布的结果。 三、损失我们的算法输出的是一个多元高斯参数分布，那损失怎么做呢？首先明确一点，我们的损失是最小化负自然对数，所以怎么生成相应的概率值很关键。这里要假定读者看过代码。并且有自己的感悟，不然我怎么写都不是很有用。还记得之前有说代码中将8帧与12帧分开了吗？我们输入前8帧，输出后12帧的分布，与预留的12帧ground truth做损失，具体公式还得自己根据代码以及相关论文推导。我就不写了，夜宵都凉了… 四、测试测试阶段就比较easy了，只要你明白了上面的算法，测试阶段无非就是将得到的概率值转化为坐标，在进行一个ADE、FDE的计算。有时候真的懂不需要多说，一点就明白。 OK,那就先写到这里，与大家共勉。"},{"title":"Hello World","date":"2022-07-12T10:44:26.614Z","url":"/2022/07/12/hello-world/","categories":[[" ",""]],"content":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post More info: Writing Run server More info: Server Generate static files More info: Generating Deploy to remote sites More info: Deployment"}]